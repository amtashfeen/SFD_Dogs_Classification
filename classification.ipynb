{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3tl9Jqtg9X0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage import img_as_ubyte\n",
        "from torchsummary import summary\n",
        "from sklearn import metrics\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNIIc53ag9X3"
      },
      "source": [
        "Cuda as device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM2PfDQlg9X5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q61RiqIEg9X5"
      },
      "source": [
        "Initial path to the stanford dogs dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zspwx1cmg9X6"
      },
      "outputs": [],
      "source": [
        "path = '/home/abdul/Desktop/projects/Blockchain'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aub2MP5Sg9X7"
      },
      "outputs": [],
      "source": [
        "train_list = []\n",
        "test_list = []\n",
        "train_label = []\n",
        "test_label = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_mVgEnGg9X7"
      },
      "source": [
        "Loading adresses of the data in lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkJh7Uuug9X8"
      },
      "outputs": [],
      "source": [
        "data = loadmat(path + '/lists/train_list.mat')\n",
        "for i in range(len(data['file_list'])):\n",
        "    train_list.append('./images/Images/'+str(data['file_list'][i][0][0]))\n",
        "    train_label.append(data['labels'][i][0]-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhHg45dcg9X9"
      },
      "outputs": [],
      "source": [
        "data1 = loadmat(path + '/lists/test_list.mat')\n",
        "for i in range(len(data1['file_list'])):\n",
        "    test_list.append('./images/Images/'+str(data1['file_list'][i][0][0]))\n",
        "    test_label.append(data1['labels'][i][0]-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVo189ikg9X-"
      },
      "source": [
        "Train data transform (Preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFqsM0qOg9X_"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmZM_Uyg9X_"
      },
      "source": [
        "Test data transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnl3uERwg9YA"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXLPbz0gg9YA"
      },
      "source": [
        "Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzwAo1J8g9YB"
      },
      "outputs": [],
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self, directory, labels, transform=transform):\n",
        "        self.dir = directory\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.image_files_list = []\n",
        "    def __len__(self):\n",
        "        return len(self.dir)\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.dir[idx])\n",
        "        img = Image.fromarray(img)\n",
        "        img = self.transform(img)\n",
        "        target = self.labels[idx]\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0i1D3UHg9YB"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqYopmbIg9YC"
      },
      "outputs": [],
      "source": [
        "trainset = DS(train_list, train_label)\n",
        "testset = DS(test_list, test_label, transform = test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flLE_1u7g9YC"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=trainset,shuffle=True, batch_size=batch_size, num_workers=8)\n",
        "test_loader = DataLoader(dataset=testset, batch_size=batch_size, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Rt5uMqg9YC"
      },
      "source": [
        "Classification model (Based on ResNet, pretrained on ImageNet dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QoA9Yb3g9YD"
      },
      "outputs": [],
      "source": [
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network,self).__init__()\n",
        "        self.n_classes = 120\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.n_inputs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "                            nn.Linear(self.n_inputs, 1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.4),\n",
        "                            nn.Linear(1024, self.n_classes),)\n",
        "    def forward(self, x):\n",
        "        out = self.resnet(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_mVgEnGg9X7"
      },
      "source": [
        "Accuracy as evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWJrvdhSg9YD"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(y_true, y_prob):\n",
        "    _,pred = torch.max(y_prob, dim=1)\n",
        "    return torch.sum(pred==y_true).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_mVgEnGg9X7"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6kSdy1sg9YD"
      },
      "outputs": [],
      "source": [
        "model = network()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_mVgEnGg9X7"
      },
      "source": [
        "Optimizer: Adam (learning rate: 1x10e-4), Loss: Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY8YxBIvg9YE"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCffedbKg9YE"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_accuracy = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbqB8c7og9YE"
      },
      "source": [
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM2dnGHjg9YE"
      },
      "outputs": [],
      "source": [
        "for i in range(epochs):\n",
        "    running_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    correct_tensor = 0\n",
        "    total = 0\n",
        "    train_ac = 0\n",
        "    total_step = len(train_loader)\n",
        "    model.train()\n",
        "    for it,(img,label) in enumerate(train_loader):\n",
        "        img = img.float()\n",
        "        label = label.long()\n",
        "        img = img.cuda()\n",
        "        label = label.cuda()\n",
        "        out = model(img)\n",
        "        loss = criterion(out,label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(out, dim=1)\n",
        "        correct_tensor += torch.sum(pred==label).item()\n",
        "        total += label.size(0)\n",
        "    epoch_accuracy = 100 * (correct_tensor / total)\n",
        "    epoch_loss = running_loss/total_step\n",
        "    train_acc.append(epoch_accuracy)\n",
        "    train_loss.append(epoch_loss)\n",
        "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(i, epoch_accuracy,epoch_loss))\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "\n",
        "    #Model Testing\n",
        "    with torch.no_grad():\n",
        "        epoch_test_loss = 0\n",
        "        epoch_test_accuracy = 0\n",
        "        model.eval()\n",
        "        for img, label in test_loader:\n",
        "            img = img.float()\n",
        "            img = img.cuda()\n",
        "            label = label.long()\n",
        "            label = label.cuda()\n",
        "            test_out = model(img)\n",
        "            t_loss = criterion(test_out, label)\n",
        "            batch_loss += t_loss.item()\n",
        "            _,pred_t = torch.max(test_out, dim=1)\n",
        "            correct_t += torch.sum(pred_t==label).item()\n",
        "            total_t += label.size(0)\n",
        "        test_epoch_acc = 100 * (correct_t / total_t)  \n",
        "        test_accuracy.append(test_epoch_acc)\n",
        "        test_epoch_loss = batch_loss/len(test_loader)\n",
        "        test_loss.append(test_epoch_loss)\n",
        "        \n",
        "        print('Test , Test_accuracy : {}, Test_loss : {}'.format(test_epoch_acc,test_epoch_loss),\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzYAit1Fg9YF"
      },
      "source": [
        "Plotting the loss and accuracy graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAk3OW2mg9YF"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss,'r', label='Training loss')\n",
        "plt.plot(test_loss, 'b', label='Test loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "# plt.savefig('loss_graph.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4_-pmcPg9YF"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_acc,'r', label='Training accuracy')\n",
        "plt.plot(test_accuracy, 'b', label='Test accuracy')\n",
        "plt.title('ACC vs Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "# plt.savefig('accuracy_graph.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
